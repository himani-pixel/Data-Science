{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2339456c-c801-45b5-8055-c10ef58b19b6",
   "metadata": {},
   "source": [
    "# Using requests module for Data Collection\n",
    "Today we will see how to scrape websites and use requests module to download the raw html of a webpage. In this section we can safely use https://quotes.toscrape.com/ and https://books.toscrape.com/ for scraping demos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9adcd13-89ee-4bfd-8ecf-67466e51e418",
   "metadata": {},
   "source": [
    "## 1. What is requests?\n",
    "- requests is a Python library used to send HTTP requests easily.\n",
    "- It allows you to fetch the content of a webpage programmatically.\n",
    "- It is commonly used as the first step before parsing HTML with BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88127fb8-0480-49d6-af6b-734e41e4ca09",
   "metadata": {},
   "source": [
    "## 2. Sending a Basic GET Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586ce2b6-c920-43ea-936a-2d5a1092ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://books.toscrape.com/\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d78f94-15a1-4db6-bd08-a1efb1937493",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (f\"HTMLS/page1.html\" , \"w\") as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecae4239-29a5-49ea-8b52-872827569292",
   "metadata": {},
   "source": [
    "## 3. Checking the Response Status\n",
    "Always check if the request was successful:\n",
    "\n",
    "`print(response.status_code)`\n",
    "\n",
    "Common Status Codes\n",
    "- `200`: OK (Success)\n",
    "- `404`: Not Found\n",
    "- `403`: Forbidden\n",
    "- `500`: Internal Server Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d2988a-0e40-403a-aaf0-0700726cdebf",
   "metadata": {},
   "source": [
    "## 4. Important Response Properties\n",
    "| Property            | Description                                   |\n",
    "|---------------------|-----------------------------------------------|\n",
    "| `response.text`       | HTML content as Unicode text                  |\n",
    "| `response.content`    | Raw bytes of the response                     |\n",
    "| `response.status_code`| HTTP status code                              |\n",
    "| `response.headers`    | Metadata like content-type, server info       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218b85f-9dbc-48ff-b6e2-ef857e9cdc9a",
   "metadata": {},
   "source": [
    "## 5. Adding Headers to Mimic a Browser\n",
    "Sometimes websites block automated requests. Adding a `User-Agent` header helps the request look like it is coming from a real browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a06d89-e624-4c7a-b9b5-1ac809d4b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db98c7-e894-4792-bc33-a42441255bf1",
   "metadata": {},
   "source": [
    "## 6. Handling Connection Errors\n",
    "Wrap your request in a try-except block to handle errors gracefully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cda45b6-a4a1-4937-884e-e11d7bc3754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = requests.get(url, timeout=5)\n",
    "    response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "    # print(response.text)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4508c0-1f2a-46c8-bf54-f43041ef65ab",
   "metadata": {},
   "source": [
    "## 7. Best Practices for Fetching Pages\n",
    "- Always check the HTTP status code.\n",
    "- Use proper headers to mimic a browser.\n",
    "- Set a timeout to avoid hanging indefinitely.\n",
    "- Respect the website by not making too many rapid requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e08f72-dde3-439d-ae3f-d180a026a725",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "- requests makes it simple to fetch web pages using Python.\n",
    "- It is the starting point for most web scraping workflows.\n",
    "- Combining requests with BeautifulSoup allows for powerful data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b6aab7f-9c64-428a-adb3-2511b4971094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 downloaded successfully.\n",
      "Page 2 downloaded successfully.\n",
      "Page 3 downloaded successfully.\n",
      "Page 4 downloaded successfully.\n",
      "Page 5 downloaded successfully.\n",
      "Page 6 downloaded successfully.\n",
      "Page 7 downloaded successfully.\n",
      "Page 8 downloaded successfully.\n",
      "Page 9 downloaded successfully.\n",
      "Page 10 downloaded successfully.\n",
      "Page 11 downloaded successfully.\n",
      "Page 12 downloaded successfully.\n",
      "Page 13 downloaded successfully.\n",
      "Page 14 downloaded successfully.\n",
      "Page 15 downloaded successfully.\n",
      "Page 16 downloaded successfully.\n",
      "Page 17 downloaded successfully.\n",
      "Page 18 downloaded successfully.\n",
      "Page 19 downloaded successfully.\n",
      "Page 20 downloaded successfully.\n",
      "Page 21 downloaded successfully.\n",
      "Page 22 downloaded successfully.\n",
      "Page 23 downloaded successfully.\n",
      "Page 24 downloaded successfully.\n",
      "Page 25 downloaded successfully.\n",
      "Page 26 downloaded successfully.\n",
      "Page 27 downloaded successfully.\n",
      "Page 28 downloaded successfully.\n",
      "Page 29 downloaded successfully.\n",
      "Page 30 downloaded successfully.\n",
      "Page 31 downloaded successfully.\n",
      "Page 32 downloaded successfully.\n",
      "Page 33 downloaded successfully.\n",
      "Page 34 downloaded successfully.\n",
      "Page 35 downloaded successfully.\n",
      "Page 36 downloaded successfully.\n",
      "Page 37 downloaded successfully.\n",
      "Page 38 downloaded successfully.\n",
      "Page 39 downloaded successfully.\n",
      "Page 40 downloaded successfully.\n",
      "Page 41 downloaded successfully.\n",
      "Page 42 downloaded successfully.\n",
      "Page 43 downloaded successfully.\n",
      "Page 44 downloaded successfully.\n",
      "Page 45 downloaded successfully.\n",
      "Page 46 downloaded successfully.\n",
      "Page 47 downloaded successfully.\n",
      "Page 48 downloaded successfully.\n",
      "Page 49 downloaded successfully.\n",
      "Page 50 downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"HTMLS\", exist_ok=True)\n",
    "\n",
    "for i in range(1, 51):\n",
    "    response = requests.get(f\"https://books.toscrape.com/catalogue/page-{i}.html\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(f\"HTMLS/page{i}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response.text)\n",
    "        print(f\"Page {i} downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Page {i} not found. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c1fffd-cf7f-488b-ab19-cdee0d2e2a28",
   "metadata": {},
   "source": [
    "### For more information check out below link:\n",
    "https://requests.readthedocs.io/en/latest/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
